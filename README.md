# Document-based Question Answering with RAG and LLM
Developed an AI-powered document-based question-answering system using Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs). The system enables users to upload documents and ask natural language questions, receiving accurate, context-based answers generated by an advanced AI model.

## Key Technologies:

1. Machine Learning / NLP: Utilized Gemini, a large language model, for natural language understanding and response generation.
2. RAG Framework: Combined document retrieval via embeddings (Gemini embeddings) and query indexing (VectorStoreIndex) with answer generation using the LLM.
3. Python Libraries: Integrated llama_index, google.generativeai, and streamlit for document processing, embedding generation, and building an interactive web app interface.
4. Custom Exception Handling: Implemented robust error management and logging for better system reliability.

## Video of the Streamlit UI

https://github.com/user-attachments/assets/19134542-f7d8-4a18-b4bb-1832ad0ba495

